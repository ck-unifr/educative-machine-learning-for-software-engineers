{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span><ul class=\"toc-item\"><li><span><a href=\"#What-is-Machine-Learning?\" data-toc-modified-id=\"What-is-Machine-Learning?-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>What is Machine Learning?</a></span><ul class=\"toc-item\"><li><span><a href=\"#Supervised-learning\" data-toc-modified-id=\"Supervised-learning-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>Supervised learning</a></span></li><li><span><a href=\"#Unsupervised-Learning\" data-toc-modified-id=\"Unsupervised-Learning-1.1.2\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>Unsupervised Learning</a></span></li></ul></li><li><span><a href=\"#ML-vs.-AI-vs.-Data-Science\" data-toc-modified-id=\"ML-vs.-AI-vs.-Data-Science-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>ML vs. AI vs. Data Science</a></span></li><li><span><a href=\"#7-Steps-of-the-Machine-Learning-Process\" data-toc-modified-id=\"7-Steps-of-the-Machine-Learning-Process-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>7 Steps of the Machine Learning Process</a></span></li></ul></li><li><span><a href=\"#Data-Manipulation-with-NumPy\" data-toc-modified-id=\"Data-Manipulation-with-NumPy-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Data Manipulation with NumPy</a></span><ul class=\"toc-item\"><li><span><a href=\"#Arrays\" data-toc-modified-id=\"Arrays-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Arrays</a></span></li><li><span><a href=\"#Basics\" data-toc-modified-id=\"Basics-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Basics</a></span><ul class=\"toc-item\"><li><span><a href=\"#arange\" data-toc-modified-id=\"arange-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>arange</a></span></li><li><span><a href=\"#linspace\" data-toc-modified-id=\"linspace-2.2.2\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>linspace</a></span></li><li><span><a href=\"#reshape\" data-toc-modified-id=\"reshape-2.2.3\"><span class=\"toc-item-num\">2.2.3&nbsp;&nbsp;</span>reshape</a></span></li><li><span><a href=\"#flatten\" data-toc-modified-id=\"flatten-2.2.4\"><span class=\"toc-item-num\">2.2.4&nbsp;&nbsp;</span>flatten</a></span></li><li><span><a href=\"#Transposing\" data-toc-modified-id=\"Transposing-2.2.5\"><span class=\"toc-item-num\">2.2.5&nbsp;&nbsp;</span>Transposing</a></span></li><li><span><a href=\"#Zeros-and-ones\" data-toc-modified-id=\"Zeros-and-ones-2.2.6\"><span class=\"toc-item-num\">2.2.6&nbsp;&nbsp;</span>Zeros and ones</a></span></li></ul></li><li><span><a href=\"#Math\" data-toc-modified-id=\"Math-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Math</a></span><ul class=\"toc-item\"><li><span><a href=\"#Arithmetic\" data-toc-modified-id=\"Arithmetic-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>Arithmetic</a></span></li><li><span><a href=\"#Non-linear-functions\" data-toc-modified-id=\"Non-linear-functions-2.3.2\"><span class=\"toc-item-num\">2.3.2&nbsp;&nbsp;</span>Non-linear functions</a></span></li><li><span><a href=\"#Matrix-multiplication\" data-toc-modified-id=\"Matrix-multiplication-2.3.3\"><span class=\"toc-item-num\">2.3.3&nbsp;&nbsp;</span>Matrix multiplication</a></span></li></ul></li><li><span><a href=\"#Random\" data-toc-modified-id=\"Random-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Random</a></span><ul class=\"toc-item\"><li><span><a href=\"#Random-integers\" data-toc-modified-id=\"Random-integers-2.4.1\"><span class=\"toc-item-num\">2.4.1&nbsp;&nbsp;</span>Random integers</a></span></li><li><span><a href=\"#Utility-functions\" data-toc-modified-id=\"Utility-functions-2.4.2\"><span class=\"toc-item-num\">2.4.2&nbsp;&nbsp;</span>Utility functions</a></span></li><li><span><a href=\"#Distributions\" data-toc-modified-id=\"Distributions-2.4.3\"><span class=\"toc-item-num\">2.4.3&nbsp;&nbsp;</span>Distributions</a></span></li><li><span><a href=\"#Custom-sampling\" data-toc-modified-id=\"Custom-sampling-2.4.4\"><span class=\"toc-item-num\">2.4.4&nbsp;&nbsp;</span>Custom sampling</a></span></li></ul></li><li><span><a href=\"#Indexing\" data-toc-modified-id=\"Indexing-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Indexing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Argmin-and-argmax\" data-toc-modified-id=\"Argmin-and-argmax-2.5.1\"><span class=\"toc-item-num\">2.5.1&nbsp;&nbsp;</span>Argmin and argmax</a></span></li></ul></li><li><span><a href=\"#Filtering\" data-toc-modified-id=\"Filtering-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>Filtering</a></span></li><li><span><a href=\"#Statistics\" data-toc-modified-id=\"Statistics-2.7\"><span class=\"toc-item-num\">2.7&nbsp;&nbsp;</span>Statistics</a></span></li><li><span><a href=\"#Aggregation\" data-toc-modified-id=\"Aggregation-2.8\"><span class=\"toc-item-num\">2.8&nbsp;&nbsp;</span>Aggregation</a></span></li><li><span><a href=\"#Saving-Data\" data-toc-modified-id=\"Saving-Data-2.9\"><span class=\"toc-item-num\">2.9&nbsp;&nbsp;</span>Saving Data</a></span></li></ul></li><li><span><a href=\"#Data-Analysis-with-pandas\" data-toc-modified-id=\"Data-Analysis-with-pandas-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Data Analysis with pandas</a></span><ul class=\"toc-item\"><li><span><a href=\"#Series\" data-toc-modified-id=\"Series-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Series</a></span></li><li><span><a href=\"#DataFrame\" data-toc-modified-id=\"DataFrame-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>DataFrame</a></span><ul class=\"toc-item\"><li><span><a href=\"#drop-rows-with-nan\" data-toc-modified-id=\"drop-rows-with-nan-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>drop rows with nan</a></span></li></ul></li><li><span><a href=\"#Combining\" data-toc-modified-id=\"Combining-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Combining</a></span></li><li><span><a href=\"#indexing\" data-toc-modified-id=\"indexing-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>indexing</a></span></li><li><span><a href=\"#File-I/O\" data-toc-modified-id=\"File-I/O-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>File I/O</a></span></li><li><span><a href=\"#Grouping\" data-toc-modified-id=\"Grouping-3.6\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span>Grouping</a></span></li><li><span><a href=\"#Features\" data-toc-modified-id=\"Features-3.7\"><span class=\"toc-item-num\">3.7&nbsp;&nbsp;</span>Features</a></span></li><li><span><a href=\"#Filtering\" data-toc-modified-id=\"Filtering-3.8\"><span class=\"toc-item-num\">3.8&nbsp;&nbsp;</span>Filtering</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Machine Learning?\n",
    "\n",
    "Machine learning is the branch of science that deals with algorithms and systems performing specific tasks using patterns and inference, rather than explicitly programmed instructions. There are a variety of different use cases for machine learning, from image recognition to text generation. Most machine learning tasks generalize to one of the following two learning types:\n",
    "\n",
    "### Supervised learning\n",
    "\n",
    "Using labeled data to train a model. The labels for the training dataset represent the class/category that each data observation belongs to. After training, the model should be able to predict labels for new data observations (from the same population distribution as the training data).\n",
    "\n",
    "Example: Let’s say you’re training a machine learning model to predict whether a picture contains a lake or not. With supervised learning, you would train a model on a dataset of pictures where the label for each picture is “Yes” if it contains a lake or “No” if it doesn’t. After training, the model will be able to take in a picture and determine whether or not it contains a lake.\n",
    "\n",
    "\n",
    "### Unsupervised Learning\n",
    "\n",
    "Using unlabeled data to allow a model to learn relationships between data observations and pick up on underlying patterns. Most data in the world is unlabeled, which makes unsupervised learning a very useful method of machine learning.\n",
    "\n",
    "Example: Going back to the same picture dataset from above, but now assume the training dataset is unlabeled. Using unsupervised learning, a model will be able to pick up on the inherent differences between pictures with a lake and pictures without a lake, e.g. differences in pixel color or orientation. This allows the model to cluster the pictures into two separate groups.\n",
    "If it is possible to get large enough labeled training datasets, supervised learning is the way to go. However, it is often difficult to get fully labeled datasets, which is why many tasks require unsupervised learning or semi-supervised learning (a mix of supervised and unsupervised learning). Deciding which type of learning method to use is only the first step towards creating a machine learning model. You also need to choose the proper model architecture for your task and, most importantly, be able to process data into a training pipeline and interpret/analyze model results.\n",
    "\n",
    "## ML vs. AI vs. Data Science\n",
    "\n",
    "People often throw around the terms “machine learning”, “artificial intelligence”, and “data science” interchangeably. In reality, machine learning is a subset of artificial intelligence and overlaps heavily with data science. Artificial intelligence deals with any technique that allows machines to display “intelligence”, similar to humans. Machine learning is one of the main techniques used to create artificial intelligence, but other non-ML techniques (e.g. alpha-beta pruning, rule-based systems) are also widely used in AI.\n",
    "\n",
    "On the other hand, data science deals with gathering insights from datasets. Traditionally, data scientists have used statistical methods for gathering these insights. However, as machine learning continues to grow, it has also penetrated into the field of data science.\n",
    "\n",
    "In industry, any data scientist or AI researcher needs to have a good understanding of machine learning. Machine learning in industry has allowed us to create wonderful autonomous systems. These systems have matched, or sometimes even exceeded, the best human performance in their respective fields. A good example is AlphaGo, a machine-learning based system that has beaten the best human Go players in the world.\n",
    "\n",
    "## 7 Steps of the Machine Learning Process\n",
    "\n",
    "Data Collection: The process of extracting raw datasets for the machine learning task. This data can come from a variety of places, ranging from open-source online resources to paid crowdsourcing. The first step of the machine learning process is arguably the most important. If the data you collect is poor quality or irrelevant, then the model you train will be poor quality as well.\n",
    "\n",
    "- Data Processing and Preparation: Once you’ve gathered the relevant data, you need to process it and make sure that it is in a usable format for training a machine learning model. This includes handling missing data, dealing with outliers, etc.\n",
    "\n",
    "- Feature Engineering: Once you’ve collected and processed your dataset, you will likely need to transform some of the features (and sometimes even drop some features) in order to optimize how well a model can be trained on the data.\n",
    "\n",
    "- Model Selection: Based on the dataset, you will choose which model architecture to use. This is one of the main tasks of industry engineers. Rather than attempting to come up with a completely novel model architecture, most tasks can be thoroughly performed with an existing architecture (or combination of model architectures).\n",
    "\n",
    "- Model Training and Data Pipeline: After selecting the model architecture, you will create a data pipeline for training the model. This means creating a continuous stream of batched data observations to efficiently train the model. Since training can take a long time, you want your data pipeline to be as efficient as possible.\n",
    "\n",
    "- Model Validation: After training the model for a sufficient amount of time, you will need to validate the model’s performance on a held-out portion of the overall dataset. This data needs to come from the same underlying distribution as the training dataset, but needs to be different data that the model has not seen before.\n",
    "\n",
    "- Model Persistence: Finally, after training and validating the model’s performance, you need to be able to properly save the model weights and possibly push the model to production. This means setting up a process with which new users can easily use your pre-trained model to make predictions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Manipulation with NumPy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([-1.,  2.,  5.], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  # import the NumPy library\n",
    "\n",
    "# Initializing a NumPy array\n",
    "arr = np.array([-1, 2, 5], dtype=np.float32)\n",
    "\n",
    "# Print the representation of the array\n",
    "print(repr(arr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n",
      "[0 1 2]\n",
      "float32\n",
      "[0. 1. 2.]\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([0, 1, 2])\n",
    "print(arr.dtype)\n",
    "print(arr)\n",
    "\n",
    "arr = arr.astype(np.float32)\n",
    "print(arr.dtype)\n",
    "print(arr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([nan,  1.,  2.])\n",
      "[nan  1.  2.]\n",
      "array(['nan', 'abc'], dtype='<U32')\n",
      "['nan' 'abc']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot convert float NaN to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2873c0c2e2f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Will result in a ValueError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: cannot convert float NaN to integer"
     ]
    }
   ],
   "source": [
    "arr = np.array([np.nan, 1, 2])\n",
    "print(repr(arr))\n",
    "print(arr)\n",
    "\n",
    "arr = np.array([np.nan, 'abc'])\n",
    "print(repr(arr))\n",
    "print(arr)\n",
    "\n",
    "# Will result in a ValueError\n",
    "np.array([np.nan, 1, 2], dtype=np.int32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infinity\n",
    "\n",
    "To represent infinity in NumPy, we use the np.inf special value. We can also represent negative infinity with -np.inf.\n",
    "\n",
    "The code below shows an example usage of np.inf. Note that np.inf cannot take on an integer type.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "array([inf,  5.])\n",
      "[inf  5.]\n",
      "array([-inf,   1.])\n",
      "[-inf   1.]\n"
     ]
    },
    {
     "ename": "OverflowError",
     "evalue": "cannot convert float infinity to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-d28686a502be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Will result in an OverflowError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mOverflowError\u001b[0m: cannot convert float infinity to integer"
     ]
    }
   ],
   "source": [
    "print(np.inf > 1000000)\n",
    "\n",
    "arr = np.array([np.inf, 5])\n",
    "print(repr(arr))\n",
    "print(arr)\n",
    "\n",
    "arr = np.array([-np.inf, 1])\n",
    "print(repr(arr))\n",
    "print(arr)\n",
    "\n",
    "# Will result in an OverflowError\n",
    "np.array([np.inf, 3], dtype=np.int32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "10.0\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([np.nan, 2, 3, 4, 5])\n",
    "\n",
    "arr2 = arr.copy()\n",
    "arr2[0] = 10\n",
    "\n",
    "print(arr[0])\n",
    "print(arr2[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.  5.4 3. ]\n",
      "[10.  2.  3.  4.  5.]\n"
     ]
    }
   ],
   "source": [
    "loat_arr = np.array([1, 5.4, 3])\n",
    "float_arr2 = arr2.astype(np.float32)\n",
    "\n",
    "print(loat_arr)\n",
    "print(float_arr2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]]\n"
     ]
    }
   ],
   "source": [
    "matrix = np.array([[1, 2, 3], [4, 5, 6]],\n",
    "                  dtype=np.float32)\n",
    "\n",
    "print(matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### arange\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([0, 1, 2, 3, 4])\n",
      "array([0., 1., 2., 3., 4., 5.])\n",
      "array([-1,  0,  1,  2,  3])\n",
      "array([-1.5,  0.5,  2.5])\n"
     ]
    }
   ],
   "source": [
    "arr = np.arange(5)\n",
    "print(repr(arr))\n",
    "\n",
    "arr = np.arange(5.1)\n",
    "print(repr(arr))\n",
    "\n",
    "arr = np.arange(-1, 4)\n",
    "print(repr(arr))\n",
    "\n",
    "arr = np.arange(-1.5, 4, 2)\n",
    "print(repr(arr))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### linspace\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To specify the number of elements in the returned array, rather than the step size, we can use the np.linspace function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([ 5.,  7.,  9., 11.])\n",
      "array([5. , 6.5, 8. , 9.5])\n",
      "array([ 5,  7,  9, 11], dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "arr = np.linspace(5, 11, num=4)\n",
    "print(repr(arr))\n",
    "\n",
    "arr = np.linspace(5, 11, num=4, endpoint=False)\n",
    "print(repr(arr))\n",
    "\n",
    "arr = np.linspace(5, 11, num=4, dtype=np.int32)\n",
    "print(repr(arr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reshape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[0, 1, 2, 3],\n",
      "       [4, 5, 6, 7]])\n",
      "New shape: (2, 4)\n",
      "array([[[0, 1],\n",
      "        [2, 3]],\n",
      "\n",
      "       [[4, 5],\n",
      "        [6, 7]]])\n",
      "New shape: (2, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "arr = np.arange(8)\n",
    "\n",
    "reshaped_arr = np.reshape(arr, (2, 4))\n",
    "print(repr(reshaped_arr))\n",
    "print('New shape: {}'.format(reshaped_arr.shape))\n",
    "\n",
    "reshaped_arr = np.reshape(arr, (-1, 2, 2))\n",
    "print(repr(reshaped_arr))\n",
    "print('New shape: {}'.format(reshaped_arr.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### flatten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[0, 1, 2, 3],\n",
      "       [4, 5, 6, 7]])\n",
      "arr shape: (2, 4)\n",
      "array([0, 1, 2, 3, 4, 5, 6, 7])\n",
      "flattened shape: (8,)\n"
     ]
    }
   ],
   "source": [
    "arr = np.arange(8)\n",
    "arr = np.reshape(arr, (2, 4))\n",
    "flattened = arr.flatten()\n",
    "print(repr(arr))\n",
    "print('arr shape: {}'.format(arr.shape))\n",
    "print(repr(flattened))\n",
    "print('flattened shape: {}'.format(flattened.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transposing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[0, 1],\n",
      "       [2, 3],\n",
      "       [4, 5],\n",
      "       [6, 7]])\n",
      "arr shape: (4, 2)\n",
      "array([[0, 2, 4, 6],\n",
      "       [1, 3, 5, 7]])\n",
      "transposed shape: (2, 4)\n"
     ]
    }
   ],
   "source": [
    "arr = np.arange(8)\n",
    "arr = np.reshape(arr, (4, 2))\n",
    "transposed = np.transpose(arr)\n",
    "print(repr(arr))\n",
    "print('arr shape: {}'.format(arr.shape))\n",
    "print(repr(transposed))\n",
    "print('transposed shape: {}'.format(transposed.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function takes in a required first argument, which will be the array we want to transpose. It also has a single keyword argument called axes, which represents the new permutation of the dimensions.\n",
    "\n",
    "The permutation is a tuple/list of integers, with the same length as the number of dimensions in the array. It tells us where to switch up the dimensions. For example, if the permutation had 3 at index 1, it means the old third dimension of the data becomes the new second dimension (since index 1 represents the second dimension).\n",
    "\n",
    "The code below shows an example usage of the np.transpose function with the axes keyword argument. The shape property gives us the shape of an array.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0  1]\n",
      "  [ 2  3]\n",
      "  [ 4  5]\n",
      "  [ 6  7]]\n",
      "\n",
      " [[ 8  9]\n",
      "  [10 11]\n",
      "  [12 13]\n",
      "  [14 15]]\n",
      "\n",
      " [[16 17]\n",
      "  [18 19]\n",
      "  [20 21]\n",
      "  [22 23]]]\n",
      "[[[ 0  8 16]\n",
      "  [ 1  9 17]]\n",
      "\n",
      " [[ 2 10 18]\n",
      "  [ 3 11 19]]\n",
      "\n",
      " [[ 4 12 20]\n",
      "  [ 5 13 21]]\n",
      "\n",
      " [[ 6 14 22]\n",
      "  [ 7 15 23]]]\n",
      "arr shape: (3, 4, 2)\n",
      "transposed shape: (4, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "arr = np.arange(24)\n",
    "arr = np.reshape(arr, (3, 4, 2))\n",
    "print(arr)\n",
    "transposed = np.transpose(arr, axes=(1, 2, 0))\n",
    "print(transposed)\n",
    "\n",
    "print('arr shape: {}'.format(arr.shape))\n",
    "print('transposed shape: {}'.format(transposed.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zeros and ones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([0., 0., 0., 0.])\n",
      "array([[1., 1., 1.],\n",
      "       [1., 1., 1.]])\n",
      "array([[1, 1, 1],\n",
      "       [1, 1, 1]], dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "arr = np.zeros(4)\n",
    "print(repr(arr))\n",
    "\n",
    "arr = np.ones((2, 3))\n",
    "print(repr(arr))\n",
    "\n",
    "arr = np.ones((2, 3), dtype=np.int32)\n",
    "print(repr(arr))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to create an array of 0's or 1's with the same shape as another array, we can use np.zeros_like and np.ones_like.\n",
    "\n",
    "The code below shows example usages of np.zeros_like and np.ones_like.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[0, 0],\n",
      "       [0, 0]])\n",
      "array([[1., 1.],\n",
      "       [1., 1.]])\n",
      "array([[1, 1],\n",
      "       [1, 1]], dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([[1, 2], [3, 4]])\n",
    "print(repr(np.zeros_like(arr)))\n",
    "\n",
    "arr = np.array([[0., 1.], [1.2, 4.]])\n",
    "print(repr(np.ones_like(arr)))\n",
    "print(repr(np.ones_like(arr, dtype=np.int32)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
      "[[[ 0  1]\n",
      "  [ 2  3]\n",
      "  [ 4  5]]\n",
      "\n",
      " [[ 6  7]\n",
      "  [ 8  9]\n",
      "  [10 11]]]\n"
     ]
    }
   ],
   "source": [
    "arr = np.arange(12)\n",
    "reshaped = np.reshape(arr, (2, 3, 2))\n",
    "\n",
    "print(arr)\n",
    "print(reshaped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
      "[[[ 0  6]\n",
      "  [ 1  7]]\n",
      "\n",
      " [[ 2  8]\n",
      "  [ 3  9]]\n",
      "\n",
      " [[ 4 10]\n",
      "  [ 5 11]]]\n"
     ]
    }
   ],
   "source": [
    "flattened = reshaped.flatten()\n",
    "transposed = np.transpose(reshaped, axes=(1, 2, 0))\n",
    "\n",
    "\n",
    "print(flattened)\n",
    "print(transposed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0.]\n",
      "[[[1 1]\n",
      "  [1 1]]\n",
      "\n",
      " [[1 1]\n",
      "  [1 1]]\n",
      "\n",
      " [[1 1]\n",
      "  [1 1]]]\n"
     ]
    }
   ],
   "source": [
    "zeros_arr = np.zeros(5)\n",
    "ones_arr = np.ones_like(transposed)\n",
    "\n",
    "print(zeros_arr)\n",
    "print(ones_arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.5  -3.45 -3.4  -3.35 -3.3  -3.25 -3.2  -3.15 -3.1  -3.05 -3.   -2.95\n",
      " -2.9  -2.85 -2.8  -2.75 -2.7  -2.65 -2.6  -2.55 -2.5  -2.45 -2.4  -2.35\n",
      " -2.3  -2.25 -2.2  -2.15 -2.1  -2.05 -2.   -1.95 -1.9  -1.85 -1.8  -1.75\n",
      " -1.7  -1.65 -1.6  -1.55 -1.5  -1.45 -1.4  -1.35 -1.3  -1.25 -1.2  -1.15\n",
      " -1.1  -1.05 -1.   -0.95 -0.9  -0.85 -0.8  -0.75 -0.7  -0.65 -0.6  -0.55\n",
      " -0.5  -0.45 -0.4  -0.35 -0.3  -0.25 -0.2  -0.15 -0.1  -0.05  0.    0.05\n",
      "  0.1   0.15  0.2   0.25  0.3   0.35  0.4   0.45  0.5   0.55  0.6   0.65\n",
      "  0.7   0.75  0.8   0.85  0.9   0.95  1.    1.05  1.1   1.15  1.2   1.25\n",
      "  1.3   1.35  1.4   1.45  1.5 ]\n"
     ]
    }
   ],
   "source": [
    "points = np.linspace(-3.5, 1.5, num=101)\n",
    "\n",
    "print(points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arithmetic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[2, 3],\n",
      "       [4, 5]])\n",
      "array([[-0.2,  0.8],\n",
      "       [ 1.8,  2.8]])\n",
      "array([[2, 4],\n",
      "       [6, 8]])\n",
      "array([[0.5, 1. ],\n",
      "       [1.5, 2. ]])\n",
      "array([[0, 1],\n",
      "       [1, 2]])\n",
      "array([[ 1,  4],\n",
      "       [ 9, 16]])\n",
      "array([[1.        , 1.41421356],\n",
      "       [1.73205081, 2.        ]])\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([[1, 2], [3, 4]])\n",
    "# Add 1 to element values\n",
    "print(repr(arr + 1))\n",
    "# Subtract element values by 1.2\n",
    "print(repr(arr - 1.2))\n",
    "# Double element values\n",
    "print(repr(arr * 2))\n",
    "# Halve element values\n",
    "print(repr(arr / 2))\n",
    "# Integer division (half)\n",
    "print(repr(arr // 2))\n",
    "# Square element values\n",
    "print(repr(arr**2))\n",
    "# Square root element values\n",
    "print(repr(arr**0.5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Celsius: array([  0., -20., -10., -40.])\n"
     ]
    }
   ],
   "source": [
    "def f2c(temps):\n",
    "    return (5/9)*(temps-32)\n",
    "\n",
    "fahrenheits = np.array([32, -4, 14, -40])\n",
    "celsius = f2c(fahrenheits)\n",
    "print('Celsius: {}'.format(repr(celsius)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-linear functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[ 2.71828183,  7.3890561 ],\n",
      "       [20.08553692, 54.59815003]])\n",
      "array([[ 2.,  4.],\n",
      "       [ 8., 16.]])\n",
      "array([[0.        , 2.30258509],\n",
      "       [1.        , 1.14472989]])\n",
      "array([[0.        , 1.        ],\n",
      "       [0.43429448, 0.49714987]])\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([[1, 2], [3, 4]])\n",
    "# Raised to power of e\n",
    "print(repr(np.exp(arr)))\n",
    "# Raised to power of 2\n",
    "print(repr(np.exp2(arr)))\n",
    "\n",
    "arr2 = np.array([[1, 10], [np.e, np.pi]])\n",
    "# Natural logarithm\n",
    "print(repr(np.log(arr2)))\n",
    "# Base 10 logarithm\n",
    "print(repr(np.log10(arr2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[ 3,  9],\n",
      "       [27, 81]])\n",
      "array([[ 10.2,  16. ],\n",
      "       [ 27. , 625. ]])\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([[1, 2], [3, 4]])\n",
    "# Raise 3 to power of each number in arr\n",
    "print(repr(np.power(3, arr)))\n",
    "arr2 = np.array([[10.2, 4], [3, 5]])\n",
    "# Raise arr2 to power of each number in arr\n",
    "print(repr(np.power(arr2, arr)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://numpy.org/doc/stable/reference/routines.math.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix multiplication\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "array([[  5,   4,  -7],\n",
      "       [  9,   8, -13],\n",
      "       [ 13,  12, -19]])\n",
      "[[  5   4  -7]\n",
      " [  9   8 -13]\n",
      " [ 13  12 -19]]\n",
      "array([[  4,   4],\n",
      "       [-11, -10]])\n",
      "[[  4   4]\n",
      " [-11 -10]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 3 is different from 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-72557c3d6f35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# This will result in ValueError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 3 is different from 2)"
     ]
    }
   ],
   "source": [
    "arr1 = np.array([1, 2, 3])\n",
    "arr2 = np.array([-3, 0, 10])\n",
    "print(np.matmul(arr1, arr2))\n",
    "\n",
    "arr3 = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "arr4 = np.array([[-1, 0, 1], [3, 2, -4]])\n",
    "print(repr(np.matmul(arr3, arr4)))\n",
    "print(np.matmul(arr3, arr4))\n",
    "print(repr(np.matmul(arr4, arr3)))\n",
    "print(np.matmul(arr4, arr3))\n",
    "# This will result in ValueError\n",
    "print(repr(np.matmul(arr3, arr3)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.5  0.8 -0.1]\n",
      " [ 0.  -1.2  1.3]]\n",
      "[[1.2 3.1]\n",
      " [1.2 0.3]\n",
      " [1.5 2.2]]\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([[-0.5, 0.8, -0.1], [0.0, -1.2, 1.3]])\n",
    "arr2 = np.array([[1.2, 3.1], [1.2, 0.3], [1.5, 2.2]])\n",
    "\n",
    "print(arr)\n",
    "print(arr2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.57079633  2.51327412 -0.31415927]\n",
      " [ 0.         -3.76991118  4.08407045]]\n",
      "[[-2.07079633  3.31327412 -0.41415927]\n",
      " [ 0.         -4.96991118  5.38407045]]\n",
      "[[ 4.28819743 10.97778541  0.1715279 ]\n",
      " [ 0.         24.70001718 28.98821461]]\n"
     ]
    }
   ],
   "source": [
    "multiplied = arr * np.pi\n",
    "added = arr + multiplied\n",
    "squared = added**2\n",
    "\n",
    "print(multiplied)\n",
    "print(added)\n",
    "print(squared)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.28350596e+01 5.85587272e+04 1.18711726e+00]\n",
      " [1.00000000e+00 5.33434578e+10 3.88527393e+12]]\n",
      "[[ 0.18232156  1.13140211]\n",
      " [ 0.18232156 -1.2039728 ]\n",
      " [ 0.40546511  0.78845736]]\n"
     ]
    }
   ],
   "source": [
    "exponential = np.exp(squared)\n",
    "logged = np.log(arr2)\n",
    "\n",
    "print(exponential)\n",
    "print(logged)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.44108036e+01  6.03529115e+10  4.39580713e+12]\n",
      " [ 1.20754286e+01 -6.42240618e+10 -4.67776415e+12]\n",
      " [ 3.03205327e+01  4.20590657e+10  3.06337283e+12]]\n",
      "[[ 1.06902790e+04 -7.04197733e+04]\n",
      " [ 1.58506868e+12  2.99914875e+12]]\n"
     ]
    }
   ],
   "source": [
    "matmul1 = np.matmul(logged, exponential)\n",
    "matmul2 = np.matmul(exponential, logged)\n",
    "\n",
    "print(matmul1)\n",
    "print(matmul2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random integers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "1\n",
      "5\n",
      "array([[ 7,  1],\n",
      "       [ 3, -2]])\n"
     ]
    }
   ],
   "source": [
    "print(np.random.randint(5))\n",
    "print(np.random.randint(5))\n",
    "print(np.random.randint(5, high=6))\n",
    "\n",
    "random_arr = np.random.randint(-3, high=14,\n",
    "                               size=(2, 2))\n",
    "print(repr(random_arr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The np.random.randint function takes in a single required argument, which actually depends on the high keyword argument. If high=None (which is the default value), then the required argument represents the upper (exclusive) end of the range, with the lower end being 0. Specifically, if the required argument is n, then the random integer is chosen uniformly from the range [0, n).\n",
    "\n",
    "If high is not None, then the required argument will represent the lower (inclusive) end of the range, while high represents the upper (exclusive) end.\n",
    "\n",
    "The size keyword argument specifies the size of the output array, where each integer in the array is randomly drawn from the specified range. As a default, np.random.randint returns a single integer.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "array([[15, 75],\n",
      "       [12, 78]])\n",
      "8\n",
      "array([[18, 75],\n",
      "       [25, 46]])\n",
      "5\n",
      "array([[15, 75],\n",
      "       [12, 78]])\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "print(np.random.randint(10))\n",
    "random_arr = np.random.randint(3, high=100,\n",
    "                               size=(2, 2))\n",
    "print(repr(random_arr))\n",
    "\n",
    "# New seed\n",
    "np.random.seed(2)\n",
    "print(np.random.randint(10))\n",
    "random_arr = np.random.randint(3, high=100,\n",
    "                               size=(2, 2))\n",
    "print(repr(random_arr))\n",
    "\n",
    "# Original seed\n",
    "np.random.seed(1)\n",
    "print(np.random.randint(10))\n",
    "random_arr = np.random.randint(3, high=100,\n",
    "                               size=(2, 2))\n",
    "print(repr(random_arr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([3, 4, 2, 5, 1])\n",
      "array([5, 3, 4, 2, 1])\n",
      "array([[4, 5, 6],\n",
      "       [7, 8, 9],\n",
      "       [1, 2, 3]])\n"
     ]
    }
   ],
   "source": [
    "vec = np.array([1, 2, 3, 4, 5])\n",
    "np.random.shuffle(vec)\n",
    "print(repr(vec))\n",
    "np.random.shuffle(vec)\n",
    "print(repr(vec))\n",
    "\n",
    "matrix = np.array([[1, 2, 3],\n",
    "                   [4, 5, 6],\n",
    "                   [7, 8, 9]])\n",
    "np.random.shuffle(matrix)\n",
    "print(repr(matrix))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3132735169322751\n",
      "0.4408281904196243\n",
      "array([0.44345289, 0.22957721, 0.53441391])\n",
      "array([[5.09984683, 0.85200471],\n",
      "       [0.60549667, 5.33388844]])\n"
     ]
    }
   ],
   "source": [
    "print(np.random.uniform())\n",
    "print(np.random.uniform(low=-1.5, high=2.2))\n",
    "print(repr(np.random.uniform(size=3)))\n",
    "print(repr(np.random.uniform(low=-3.4, high=5.9,\n",
    "                             size=(2, 2))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function np.random.uniform actually has no required arguments. The keyword arguments, low and high, represent the inclusive lower end and exclusive upper end from which to draw random samples. Since they have default values of 0.0 and 1.0, respectively, the default outputs of np.random.uniform come from the range [0.0, 1.0).\n",
    "\n",
    "The size keyword argument is the same as the one for np.random.randint, i.e. it represents the output size of the array.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7252740646272712\n",
      "4.772112039383628\n",
      "array([[ 2.07318791, -2.17754724],\n",
      "       [-0.89337346, -0.89545991]])\n"
     ]
    }
   ],
   "source": [
    "print(np.random.normal())\n",
    "print(np.random.normal(loc=1.5, scale=3.5))\n",
    "print(repr(np.random.normal(loc=-2.4, scale=4.0,\n",
    "                            size=(2, 2))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like np.random.uniform, np.random.normal has no required arguments. The loc and scale keyword arguments represent the mean and standard deviation, respectively, of the normal distribution we sample from.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "green\n",
      "array(['blue', 'red'], dtype='<U5')\n",
      "array([['red', 'red'],\n",
      "       ['blue', 'red']], dtype='<U5')\n"
     ]
    }
   ],
   "source": [
    "colors = ['red', 'blue', 'green']\n",
    "print(np.random.choice(colors))\n",
    "print(repr(np.random.choice(colors, size=2)))\n",
    "print(repr(np.random.choice(colors, size=(2, 2),\n",
    "                            p=[0.8, 0.19, 0.01])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "[[3 4 6 7 5]\n",
      " [7 3 8 6 4]\n",
      " [5 3 7 4 5]]\n"
     ]
    }
   ],
   "source": [
    "random1 = np.random.randint(5)\n",
    "random_arr = np.random.randint(3, high=10, size=(3, 5))\n",
    "\n",
    "\n",
    "print(random1)\n",
    "print(random_arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.65711731 -2.08709597 -0.7084259   1.13438201 -1.32554341]\n"
     ]
    }
   ],
   "source": [
    "random_uniform = np.random.uniform(low=-2.5, high=1.5, size=5)\n",
    "\n",
    "print(random_uniform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.42081263  0.61136266 -0.40510445 -0.95821975 -0.34936146]\n",
      " [ 1.9556739  -1.91058622  2.82045494  7.80930762  4.59715456]\n",
      " [ 1.32857557 -1.10670137 -0.61505403  7.9235911   2.17782714]\n",
      " [-0.22948476  2.6682042   9.35089298  2.42055633  4.16021088]\n",
      " [ 3.05059612  0.76712554 -1.99881369  0.77730047  1.26887018]\n",
      " [ 4.05318117  4.93644195  5.25885728  2.99955564  5.09799407]\n",
      " [-0.64039279  6.38503854  3.79525437  0.95667508  3.70981351]\n",
      " [ 1.735499    5.96070286  7.31935886  9.64951392 -2.88773717]\n",
      " [-3.05439832  0.23436948  2.56012974  5.06659122  3.10472232]\n",
      " [-5.07770426  0.92828596  4.89791125  2.80533157  4.66703913]]\n"
     ]
    }
   ],
   "source": [
    "random_norm = np.random.normal(loc=2.0, scale=3.5, size=(10, 5))\n",
    "print(random_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "choices = ['a', 'b', 'c', 'd']\n",
    "choice = np.random.choice(choices, p=[0.5, 0.1, 0.2, 0.2])\n",
    "\n",
    "print(choice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 3 4 2 1]\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([1, 2, 3, 4, 5])\n",
    "np.random.shuffle(arr)\n",
    "\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "5\n",
      "array([6, 3])\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([1, 2, 3, 4, 5])\n",
    "print(arr[0])\n",
    "print(arr[4])\n",
    "\n",
    "arr = np.array([[6, 3], [0, 2]])\n",
    "# Subarray\n",
    "print(repr(arr[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([1, 2, 3, 4, 5])\n",
      "array([2, 3, 4, 5])\n",
      "array([3, 4])\n",
      "array([1, 2, 3, 4])\n",
      "array([4, 5])\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([1, 2, 3, 4, 5])\n",
    "print(repr(arr[:]))\n",
    "print(repr(arr[1:]))\n",
    "print(repr(arr[2:4]))\n",
    "print(repr(arr[:-1]))\n",
    "print(repr(arr[-2:]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Argmin and argmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([[-2, -1, -3],\n",
    "                [4, 5, -6],\n",
    "                [-3, 9, 1]])\n",
    "print(np.argmin(arr[0]))\n",
    "print(np.argmax(arr[2]))\n",
    "print(np.argmin(arr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([2, 0, 1])\n",
      "array([2, 2, 0])\n",
      "array([1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([[-2, -1, -3],\n",
    "                [4, 5, -6],\n",
    "                [-3, 9, 1]])\n",
    "print(repr(np.argmin(arr, axis=0)))\n",
    "print(repr(np.argmin(arr, axis=1)))\n",
    "print(repr(np.argmax(arr, axis=-1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[False, False,  True],\n",
      "       [False,  True, False],\n",
      "       [False, False, False]])\n",
      "array([[False,  True,  True],\n",
      "       [ True,  True, False],\n",
      "       [False, False,  True]])\n",
      "array([[ True,  True,  True],\n",
      "       [False,  True,  True],\n",
      "       [ True,  True, False]])\n",
      "array([[False, False, False],\n",
      "       [ True, False, False],\n",
      "       [False, False,  True]])\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([[0, 2, 3],\n",
    "                [1, 3, -6],\n",
    "                [-3, -2, 1]])\n",
    "print(repr(arr == 3))\n",
    "print(repr(arr > 0))\n",
    "print(repr(arr != 1))\n",
    "# Negated from the previous step\n",
    "print(repr(~(arr != 1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[False, False,  True],\n",
      "       [False,  True, False],\n",
      "       [ True, False, False]])\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([[0, 2, np.nan],\n",
    "                [1, np.nan, -6],\n",
    "                [np.nan, -2, 1]])\n",
    "print(repr(np.isnan(arr)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 2]),)\n",
      "(array([1, 3]),)\n",
      "array([0, 0, 1, 2])\n",
      "array([1, 2, 0, 0])\n",
      "array([ 2,  3,  1, -3])\n"
     ]
    }
   ],
   "source": [
    "print(repr(np.where([True, False, True])))\n",
    "\n",
    "arr = np.array([0, 3, 5, 3, 1])\n",
    "print(repr(np.where(arr == 3)))\n",
    "\n",
    "arr = np.array([[0, 2, 3],\n",
    "                [1, 0, 0],\n",
    "                [-3, 0, 0]])\n",
    "x_ind, y_ind = np.where(arr != 0)\n",
    "print(repr(x_ind)) # x indices of non-zero elements\n",
    "print(repr(y_ind)) # y indices of non-zero elements\n",
    "print(repr(arr[x_ind, y_ind]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The interesting thing about np.where is that it must be applied with exactly 1 or 3 arguments. When we use 3 arguments, the first argument is still the boolean array. However, the next two arguments represent the True replacement values and the False replacement values, respectively. The output of the function now becomes an array with the same shape as the first argument.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[ 1, -5],\n",
      "       [-1,  4]])\n",
      "array([[-2, -5],\n",
      "       [ 3,  4]])\n",
      "array([[-2, -5],\n",
      "       [-1, -8]])\n"
     ]
    }
   ],
   "source": [
    "np_filter = np.array([[True, False], [False, True]])\n",
    "positives = np.array([[1, 2], [3, 4]])\n",
    "negatives = np.array([[-2, -5], [-1, -8]])\n",
    "print(repr(np.where(np_filter, positives, negatives)))\n",
    "\n",
    "np_filter = positives > 2\n",
    "print(repr(np.where(np_filter, positives, negatives)))\n",
    "\n",
    "np_filter = negatives > 0\n",
    "print(repr(np.where(np_filter, positives, negatives)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[ 1, -1],\n",
      "       [-1,  4]])\n"
     ]
    }
   ],
   "source": [
    "np_filter = np.array([[True, False], [False, True]])\n",
    "positives = np.array([[1, 2], [3, 4]])\n",
    "print(repr(np.where(np_filter, positives, -1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[False, False, False],\n",
      "       [ True,  True, False],\n",
      "       [ True,  True,  True]])\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([[-2, -1, -3],\n",
    "                [4, 5, -6],\n",
    "                [3, 9, 1]])\n",
    "print(repr(arr > 0))\n",
    "print(np.any(arr > 0))\n",
    "print(np.all(arr > 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[False, False, False],\n",
      "       [ True,  True, False],\n",
      "       [ True,  True,  True]])\n",
      "array([ True,  True,  True])\n",
      "array([False,  True,  True])\n",
      "array([False, False,  True])\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([[-2, -1, -3],\n",
    "                [4, 5, -6],\n",
    "                [3, 9, 1]])\n",
    "print(repr(arr > 0))\n",
    "print(repr(np.any(arr > 0, axis=0)))\n",
    "print(repr(np.any(arr > 0, axis=1)))\n",
    "print(repr(np.all(arr > 0, axis=1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The np.any function is equivalent to performing a logical OR (||), while the np.all function is equivalent to a logical AND (&&) on the first argument. np.any returns true if even one of the elements in the array meets the condition and np.all returns true only if all the elements meet the condition. When only a single argument is passed in, the function is applied across the entire input array, so the returned value is a single boolean.\n",
    "\n",
    "However, if we use a multi-dimensional input and specify the axis keyword argument, the returned value will be an array. The axis argument has the same meaning as it did for np.argmin and np.argmax from the previous chapter. Using axis=0 means the function finds the index of the minimum row element for each column. When we used axis=1, the function finds the index of the minimum column element for each row.\n",
    "\n",
    "Setting axis to -1 just means we apply the function across the last dimension.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True  True]\n",
      "array([[ 4,  5, -6],\n",
      "       [ 3,  9,  1]])\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([[-2, -1, -3],\n",
    "                [4, 5, -6],\n",
    "                [3, 9, 1]])\n",
    "has_positive = np.any(arr > 0, axis=1)\n",
    "print(has_positive)\n",
    "print(repr(arr[np.where(has_positive)]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-60\n",
      "72\n",
      "array([ -3,  -2, -60])\n",
      "array([72,  3,  4])\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([[0, 72, 3],\n",
    "                [1, 3, -60],\n",
    "                [-3, -2, 4]])\n",
    "print(arr.min())\n",
    "print(arr.max())\n",
    "\n",
    "print(repr(arr.min(axis=0)))\n",
    "print(repr(arr.max(axis=-1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([ -3,  -2, -60])\n"
     ]
    }
   ],
   "source": [
    "print(repr(arr.min(axis=0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([  0, -60,  -3])\n"
     ]
    }
   ],
   "source": [
    "print(repr(arr.min(axis=1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The axis keyword argument is identical to how it was used in np.argmin and np.argmax from the chapter on Indexing. In our example, we use axis=0 to find an array of the minimum values in each column of arr and axis=1 to find an array of the maximum values in each row of arr.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n",
      "977.3333333333334\n",
      "1.0\n",
      "[0. 3. 3.]\n",
      "[ 3.  1. -2.]\n",
      "[ 3.  1. -2.]\n",
      "array([ 3.,  1., -2.])\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([[0, 72, 3],\n",
    "                [1, 3, -60],\n",
    "                [-3, -2, 4]])\n",
    "print(np.mean(arr))\n",
    "print(np.var(arr))\n",
    "print(np.median(arr))\n",
    "print(np.median(arr, axis=0))\n",
    "print(np.median(arr, axis=1))\n",
    "print(np.median(arr, axis=-1))\n",
    "print(repr(np.median(arr, axis=-1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "array([ -2,  73, -53])\n",
      "array([ 75, -56,  -1])\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([[0, 72, 3],\n",
    "                [1, 3, -60],\n",
    "                [-3, -2, 4]])\n",
    "print(np.sum(arr))\n",
    "print(repr(np.sum(arr, axis=0)))\n",
    "print(repr(np.sum(arr, axis=1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([ 0, 72, 75, 76, 79, 19, 16, 14, 18])\n",
      "array([[  0,  72,   3],\n",
      "       [  1,  75, -57],\n",
      "       [ -2,  73, -53]])\n",
      "array([[  0,  72,  75],\n",
      "       [  1,   4, -56],\n",
      "       [ -3,  -5,  -1]])\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([[0, 72, 3],\n",
    "                [1, 3, -60],\n",
    "                [-3, -2, 4]])\n",
    "print(repr(np.cumsum(arr)))\n",
    "print(repr(np.cumsum(arr, axis=0)))\n",
    "print(repr(np.cumsum(arr, axis=1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to regular sums, NumPy can perform cumulative sums using np.cumsum. Like np.sum, np.cumsum also takes in a NumPy array as a required argument and uses the axis argument. If the axis keyword argument is not specified, np.cumsum will return the cumulative sums for the flattened array.\n",
    "\n",
    "The code below shows how to use np.cumsum. For a 2-D NumPy array, setting axis=0 returns an array with cumulative sums across each column, while axis=1 returns the array with cumulative sums across each row. Not setting axis returns a cumulative sum across all the values of the flattened array.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[  0,  72,   3],\n",
      "       [  1,   3, -60],\n",
      "       [ -3,  -2,   4],\n",
      "       [-15,   6,   1],\n",
      "       [  8,   9,  -4],\n",
      "       [  5, -21,  18]])\n",
      "array([[  0,  72,   3, -15,   6,   1],\n",
      "       [  1,   3, -60,   8,   9,  -4],\n",
      "       [ -3,  -2,   4,   5, -21,  18]])\n",
      "array([[-15,   6,   1,   0,  72,   3],\n",
      "       [  8,   9,  -4,   1,   3, -60],\n",
      "       [  5, -21,  18,  -3,  -2,   4]])\n"
     ]
    }
   ],
   "source": [
    "arr1 = np.array([[0, 72, 3],\n",
    "                 [1, 3, -60],\n",
    "                 [-3, -2, 4]])\n",
    "arr2 = np.array([[-15, 6, 1],\n",
    "                 [8, 9, -4],\n",
    "                 [5, -21, 18]])\n",
    "print(repr(np.concatenate([arr1, arr2])))\n",
    "print(repr(np.concatenate([arr1, arr2], axis=1)))\n",
    "print(repr(np.concatenate([arr2, arr1], axis=1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important part of aggregation is combining multiple datasets. In NumPy, this equates to combining multiple arrays into one. The function we use to do this is np.concatenate.\n",
    "\n",
    "Like the summation functions, np.concatenate uses the axis keyword argument. However, the default value for axis is 0 (i.e. dimension 0). Furthermore, the required argument for np.concatenate is a list of arrays, which the function combines into a single array.\n",
    "\n",
    "The code below shows how to use np.concatenate, which aggregates arrays by joining them along a specific dimension. For 2-D arrays, not setting the axis argument (defaults to axis=0) concatenates the arrays vertically. When we set axis=1, the arrays are concatenated horizontally.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([1, 2, 3])\n",
    "\n",
    "# Saves to 'arr.npy'\n",
    "#np.save('arr.npy', arr)\n",
    "\n",
    "# Also saves to 'arr.npy'\n",
    "#np.save('arr', arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([1, 2, 3])\n",
    "\n",
    "#np.save('arr.npy', arr)\n",
    "#load_arr = np.load('arr.npy')\n",
    "#print(repr(load_arr))\n",
    "\n",
    "# Will result in FileNotFoundError\n",
    "#load_arr = np.load('arr')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis with pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to NumPy, pandas frequently deals with 1-D and 2-D data. However, we use two separate objects to deal with 1-D and 2-D data in pandas. For 1-D data, we use the pandas.Series objects, which we'll refer to simply as a Series.\n",
    "\n",
    "A Series is created through the pd.Series constructor, which takes in no required arguments but does have a variety of keyword arguments.\n",
    "\n",
    "The first keyword argument is data, which specifies the elements of the Series. If data is not set, pd.Series returns an empty Series. Since the data keyword argument is almost always used, we treat it like a regular first argument (i.e. skip the data= prefix).\n",
    "\n",
    "Similar to the np.array constructor, pd.Series also takes in the dtype keyword argument for manual casting.\n",
    "\n",
    "The code below shows how to create pandas Series objects using pd.Series.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: float64)\n",
      "\n",
      "0    5\n",
      "dtype: int64\n",
      "\n",
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "dtype: int64\n",
      "\n",
      "0    1.0\n",
      "1    2.2\n",
      "dtype: float64\n",
      "\n",
      "0    1.0\n",
      "1    2.0\n",
      "dtype: float32\n",
      "\n",
      "0    [1, 2]\n",
      "1    [3, 4]\n",
      "dtype: object\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kai/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "series = pd.Series()\n",
    "# Newline to separate series print statements\n",
    "print('{}\\n'.format(series))\n",
    "\n",
    "series = pd.Series(5)\n",
    "print('{}\\n'.format(series))\n",
    "\n",
    "series = pd.Series([1, 2, 3])\n",
    "print('{}\\n'.format(series))\n",
    "\n",
    "series = pd.Series([1, 2.2]) # upcasting\n",
    "print('{}\\n'.format(series))\n",
    "\n",
    "arr = np.array([1, 2])\n",
    "series = pd.Series(arr, dtype=np.float32)\n",
    "print('{}\\n'.format(series))\n",
    "\n",
    "series = pd.Series([[1, 2], [3, 4]])\n",
    "print('{}\\n'.format(series))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous examples, you may have noticed the zero-indexed integers to the left of the elements in each Series. These integers are collectively referred to as the index of a Series, and each individual index element is referred to as a label.\n",
    "\n",
    "The default index is integers from 0 to n - 1, where n is the number of elements in the Series. However, we can specify a custom index via the index keyword argument of pd.Series.\n",
    "\n",
    "The code below shows how to use the index keyword argument with pd.Series.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    1\n",
      "b    2\n",
      "c    3\n",
      "dtype: int64\n",
      "\n",
      "a      1\n",
      "8      2\n",
      "0.3    3\n",
      "dtype: int64\n",
      "\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "series = pd.Series([1, 2, 3], index=['a', 'b', 'c'])\n",
    "print('{}\\n'.format(series))\n",
    "\n",
    "series = pd.Series([1, 2, 3], index=['a', 8, 0.3])\n",
    "print('{}\\n'.format(series))\n",
    "\n",
    "print(series['a'])\n",
    "print(series[8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to set the index of a Series is by using a Python dictionary for the data argument. The keys of the dictionary represent the index of the Series, while each individual key is the label for its corresponding value.\n",
    "\n",
    "The code below shows how to use pd.Series with a Python dictionary as the first argument. In our example, we set 'a', 'b', and 'c' as the Series index, with corresponding values 1, 2, and 3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    1\n",
      "b    2\n",
      "c    3\n",
      "dtype: int64\n",
      "\n",
      "b    2\n",
      "a    1\n",
      "c    3\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "series = pd.Series({'a':1, 'b':2, 'c':3})\n",
    "print('{}\\n'.format(series))\n",
    "\n",
    "series = pd.Series({'b':2, 'a':1, 'c':3})\n",
    "print('{}\\n'.format(series))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the main purposes of pandas is to deal with tabular data, i.e. data that comes from tables or spreadsheets. Since tabular data contains rows and columns, it is 2-D. For working with 2-D data, we use the pandas.DataFrame object, which we'll refer to simply as a DataFrame.\n",
    "\n",
    "A DataFrame is created through the pd.DataFrame constructor, which takes in essentially the same arguments as pd.Series. However, while a Series could be constructed from a scalar (representing a single value Series), a DataFrame cannot.\n",
    "\n",
    "Furthermore, pd.DataFrame takes in an additional columns keyword argument, which represents the labels for the columns (similar to how index represents the row labels).\n",
    "\n",
    "The code below shows how to use the pd.DataFrame constructor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "\n",
      "   0\n",
      "0  5\n",
      "1  6\n",
      "\n",
      "   0  1\n",
      "0  5  6\n",
      "\n",
      "    c1  c2\n",
      "r1   5   6\n",
      "r2   1   3\n",
      "\n",
      "    c1  c2\n",
      "r1   1   3\n",
      "r2   2   4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "# Newline added to separate DataFrames\n",
    "print('{}\\n'.format(df))\n",
    "\n",
    "df = pd.DataFrame([5, 6])\n",
    "print('{}\\n'.format(df))\n",
    "\n",
    "df = pd.DataFrame([[5,6]])\n",
    "print('{}\\n'.format(df))\n",
    "\n",
    "df = pd.DataFrame([[5, 6], [1, 3]],\n",
    "                  index=['r1', 'r2'],\n",
    "                  columns=['c1', 'c2'])\n",
    "print('{}\\n'.format(df))\n",
    "\n",
    "df = pd.DataFrame({'c1': [1, 2], 'c2': [3, 4]},\n",
    "                  index=['r1', 'r2'])\n",
    "print('{}\\n'.format(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0  1\n",
      "0  5.0  6\n",
      "1  1.2  3\n",
      "\n",
      "0    float64\n",
      "1      int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "upcast = pd.DataFrame([[5, 6], [1.2, 3]])\n",
    "print('{}\\n'.format(upcast))\n",
    "# Datatypes of each column\n",
    "print(upcast.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can append additional rows to a given DataFrame through the append function. The required argument for the function is either a Series or DataFrame, representing the row(s) we append.\n",
    "\n",
    "Note that the append function returns the modified DataFrame but doesn't actually change the original. Furthermore, when we append a Series to the DataFrame, we either need to specify the name for the series or use the ignore_index keyword argument. Setting ignore_index=True will change the row labels to integer indexes.\n",
    "\n",
    "The code below shows example usages of the append function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0  1\n",
      "0   5.0  6\n",
      "1   1.2  3\n",
      "r3  0.0  0\n",
      "\n",
      "     0  1\n",
      "0  5.0  6\n",
      "1  1.2  3\n",
      "2  0.0  0\n",
      "\n",
      "     0  1\n",
      "0  5.0  6\n",
      "1  1.2  3\n",
      "0  0.0  0\n",
      "1  9.0  9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame([[5, 6], [1.2, 3]])\n",
    "ser = pd.Series([0, 0], name='r3')\n",
    "\n",
    "df_app = df.append(ser)\n",
    "print('{}\\n'.format(df_app))\n",
    "\n",
    "df_app = df.append(ser, ignore_index=True)\n",
    "print('{}\\n'.format(df_app))\n",
    "\n",
    "df2 = pd.DataFrame([[0,0],[9,9]])\n",
    "df_app = df.append(df2)\n",
    "print('{}\\n'.format(df_app))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can drop rows or columns from a given DataFrame through the drop function. There is no required argument, but the keyword arguments of the function gives us two ways to drop rows/columns from a DataFrame.\n",
    "\n",
    "The first way is using the labels keyword argument to specify the labels of the rows/columns we want to drop. We use this alongside the axis keyword argument (which has default value of 0) to drop from the rows or columns axis.\n",
    "\n",
    "The second method is to directly use the index or columns keyword arguments to specify the labels of the rows or columns directly, without needing to use axis.\n",
    "\n",
    "The code below shows examples on how to use the drop function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    c1  c2  c3\n",
      "r2   2   4   6\n",
      "\n",
      "    c2\n",
      "r1   3\n",
      "r2   4\n",
      "\n",
      "    c1  c2  c3\n",
      "r1   1   3   5\n",
      "\n",
      "    c1  c3\n",
      "r1   1   5\n",
      "r2   2   6\n",
      "\n",
      "    c1  c3\n",
      "r1   1   5\n",
      "r2   2   6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'c1': [1, 2], 'c2': [3, 4],\n",
    "                   'c3': [5, 6]},\n",
    "                  index=['r1', 'r2'])\n",
    "# Drop row r1\n",
    "df_drop = df.drop(labels='r1')\n",
    "print('{}\\n'.format(df_drop))\n",
    "\n",
    "# Drop columns c1, c3\n",
    "df_drop = df.drop(labels=['c1', 'c3'], axis=1)\n",
    "print('{}\\n'.format(df_drop))\n",
    "\n",
    "df_drop = df.drop(index='r2')\n",
    "print('{}\\n'.format(df_drop))\n",
    "\n",
    "df_drop = df.drop(columns='c2')\n",
    "print('{}\\n'.format(df_drop))\n",
    "\n",
    "df.drop(index='r2', columns='c2')\n",
    "print('{}\\n'.format(df_drop))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drop rows with nan\n",
    "\n",
    "df = df[df['col'].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to append, the drop function returns the modified DataFrame but doesn't actually change the original.\n",
    "\n",
    "Note that when using labels and axis, we can't drop both rows and columns from the DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous chapter, we discussed the append function for concatenating DataFrame rows. To concatenate multiple DataFrames along either rows or columns, we use the pd.concat function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    c1  c2  c1  c2\n",
      "r1   1   3   5   7\n",
      "r2   2   4   6   8\n",
      "\n",
      "    c1  c2\n",
      "r1   5   7\n",
      "r2   6   8\n",
      "r1   1   3\n",
      "r2   2   4\n",
      "0    5   7\n",
      "1    6   8\n",
      "\n",
      "     c1   c2   c1   c2\n",
      "r1  1.0  3.0  NaN  NaN\n",
      "r2  2.0  4.0  NaN  NaN\n",
      "0   NaN  NaN  5.0  7.0\n",
      "1   NaN  NaN  6.0  8.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame({'c1':[1,2], 'c2':[3,4]},\n",
    "                   index=['r1','r2'])\n",
    "df2 = pd.DataFrame({'c1':[5,6], 'c2':[7,8]},\n",
    "                   index=['r1','r2'])\n",
    "df3 = pd.DataFrame({'c1':[5,6], 'c2':[7,8]})\n",
    "\n",
    "concat = pd.concat([df1, df2], axis='columns')\n",
    "#concat = pd.concat([df1, df2], axis=1)\n",
    "# Newline to separate print statements\n",
    "print('{}\\n'.format(concat))\n",
    "\n",
    "concat = pd.concat([df2, df1, df3])\n",
    "print('{}\\n'.format(concat))\n",
    "\n",
    "concat = pd.concat([df1, df3], axis=1)\n",
    "print('{}\\n'.format(concat))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pd.concat function takes in a list of pandas objects (normally a list of DataFrames) to concatenate. The function also takes in numerous keyword arguments, with axis being one of the more important ones. The axis argument specifies whether we concatenate the rows (axis=0, the default), or concatenate the columns (axis=1).\n",
    "\n",
    "This works very similarly to concatenation in NumPy\n",
    "In the code example, the final call to pd.concat resulted in a DataFrame with many NaN values. This is because the row labels for df1 and df3 did not match, so result was padded with NaN in locations where values did not exist.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        name pos  year\n",
      "0   john doe  1B  2000\n",
      "1   al smith   C  2004\n",
      "2  sam black   P  2008\n",
      "3   john doe  2B  2003\n",
      "\n",
      "        name pos  year\n",
      "0   john doe  1B  2000\n",
      "1   al smith   C  2004\n",
      "2  sam black   P  2008\n",
      "3   john doe  2B  2003\n",
      "\n",
      "       name pos  year  rbi\n",
      "0  john doe  1B  2000   80\n",
      "1  al smith   C  2004  100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlb_df1 = pd.DataFrame({'name': ['john doe', 'al smith', 'sam black', 'john doe'],\n",
    "                        'pos': ['1B', 'C', 'P', '2B'],\n",
    "                        'year': [2000, 2004, 2008, 2003]})\n",
    "mlb_df2 = pd.DataFrame({'name': ['john doe', 'al smith', 'jack lee'],\n",
    "                        'year': [2000, 2004, 2012],\n",
    "                        'rbi': [80, 100, 12]})\n",
    "                        \n",
    "print('{}\\n'.format(mlb_df1))\n",
    "print('{}\\n'.format(mlb_df1))\n",
    "\n",
    "mlb_merged = pd.merge(mlb_df1, mlb_df2)\n",
    "print('{}\\n'.format(mlb_merged))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## indexing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r1    1\n",
      "r2    2\n",
      "Name: c1, dtype: int64\n",
      "\n",
      "    c1\n",
      "r1   1\n",
      "r2   2\n",
      "\n",
      "    c2  c3\n",
      "r1   3   5\n",
      "r2   4   6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'c1': [1, 2], 'c2': [3, 4],\n",
    "                   'c3': [5, 6]}, index=['r1', 'r2'])\n",
    "col1 = df['c1']\n",
    "# Newline for separating print statements\n",
    "print('{}\\n'.format(col1))\n",
    "\n",
    "col1_df = df[['c1']]\n",
    "print('{}\\n'.format(col1_df))\n",
    "\n",
    "col23 = df[['c2', 'c3']]\n",
    "print('{}\\n'.format(col23))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that when we use a single column label inside the bracket (as was the case for col1 in the code example), the output is a Series representing the corresponding column. When we use a list of column labels (as was the case for col1_df and col23), the output is a DataFrame that contains the corresponding columns.\n",
    "\n",
    "We can also use direct indexing to retrieve a subset of the rows (as a DataFrame). However, we can only retrieve rows based on slices, rather than specifying particular rows.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    c1  c2  c3\n",
      "r1   1   4   7\n",
      "r2   2   5   8\n",
      "r3   3   6   9\n",
      "\n",
      "    c1  c2  c3\n",
      "r1   1   4   7\n",
      "r2   2   5   8\n",
      "\n",
      "    c1  c2  c3\n",
      "r2   2   5   8\n",
      "r3   3   6   9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'c1': [1, 2, 3], 'c2': [4, 5, 6],\n",
    "                   'c3': [7, 8, 9]}, index=['r1', 'r2', 'r3'])\n",
    "\n",
    "print('{}\\n'.format(df))\n",
    "\n",
    "first_two_rows = df[0:2]\n",
    "print('{}\\n'.format(first_two_rows))\n",
    "\n",
    "last_two_rows = df['r2':'r3']\n",
    "print('{}\\n'.format(last_two_rows))\n",
    "\n",
    "# Results in KeyError\n",
    "#df['r1']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that when we used integer indexing for the rows, the end index was exclusive (e.g. first_two_rows excluded the row at index 2). However, when we use row labels, the end index is inclusive (e.g. last_two_rows included the row labeled 'r3').\n",
    "\n",
    "Furthermore, when we tried to retrieve a single row based on its label, we received a KeyError. This is because the DataFrame treated 'r1' as a column label.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from direct indexing, a DataFrame object also contains the loc and iloc properties for indexing.\n",
    "\n",
    "We use iloc to access rows based on their integer index. Using iloc we can access a single row as a Series, and specify particular rows to access through a list of integers or a boolean array.\n",
    "\n",
    "The code below shows how to use iloc to access a DataFrame's rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    c1  c2  c3\n",
      "r1   1   4   7\n",
      "r2   2   5   8\n",
      "r3   3   6   9\n",
      "\n",
      "c1    2\n",
      "c2    5\n",
      "c3    8\n",
      "Name: r2, dtype: int64\n",
      "\n",
      "    c1  c2  c3\n",
      "r1   1   4   7\n",
      "r3   3   6   9\n",
      "\n",
      "    c1  c2  c3\n",
      "r2   2   5   8\n",
      "r3   3   6   9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('{}\\n'.format(df))\n",
    "\n",
    "print('{}\\n'.format(df.iloc[1]))\n",
    "\n",
    "print('{}\\n'.format(df.iloc[[0, 2]]))\n",
    "\n",
    "bool_list = [False, True, True]\n",
    "print('{}\\n'.format(df.iloc[bool_list]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loc property provides the same row indexing functionality as iloc, but uses row labels rather than integer indexes. Furthermore, with loc we can perform column indexing along with row indexing, and set new values in a DataFrame for specific rows and columns.\n",
    "\n",
    "The code below shows example usages of loc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    c1  c2  c3\n",
      "r1   1   4   7\n",
      "r2   2   5   8\n",
      "r3   3   6   9\n",
      "\n",
      "c1    2\n",
      "c2    5\n",
      "c3    8\n",
      "Name: r2, dtype: int64\n",
      "\n",
      "    c1  c2  c3\n",
      "r2   2   5   8\n",
      "r3   3   6   9\n",
      "\n",
      "Single val: 4\n",
      "\n",
      "r1    4\n",
      "r3    6\n",
      "Name: c2, dtype: int64\n",
      "\n",
      "    c1  c2  c3\n",
      "r1   1   0   7\n",
      "r2   2   5   8\n",
      "r3   3   0   9\n",
      "\n",
      "1\n",
      "1\n",
      "1\n",
      "r1    0\n",
      "r2    5\n",
      "Name: c2, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'c1': [1, 2, 3], 'c2': [4, 5, 6],\n",
    "                   'c3': [7, 8, 9]}, index=['r1', 'r2', 'r3'])\n",
    "                   \n",
    "print('{}\\n'.format(df))\n",
    "\n",
    "print('{}\\n'.format(df.loc['r2']))\n",
    "\n",
    "bool_list = [False, True, True]\n",
    "print('{}\\n'.format(df.loc[bool_list]))\n",
    "\n",
    "single_val = df.loc['r1', 'c2']\n",
    "print('Single val: {}\\n'.format(single_val))\n",
    "\n",
    "print('{}\\n'.format(df.loc[['r1', 'r3'], 'c2']))\n",
    "\n",
    "df.loc[['r1', 'r3'], 'c2'] = 0\n",
    "print('{}\\n'.format(df))\n",
    "\n",
    "\n",
    "print(df.iloc[0]['c1'])\n",
    "print(df.iloc[0, 0])\n",
    "print(df.loc['r1', 'c1'])\n",
    "print(df.loc[['r1', 'r2'], 'c2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that the way we access rows and columns together with loc is similar to how we access 2-D NumPy arrays.\n",
    "\n",
    "Since we can't access columns on their own with loc or iloc, we still use bracket indexing when retrieving columns of a DataFrame.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File I/O\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats_df = pd.read_csv('stats.csv')\n",
    "# salary_df = pd.read_csv('salary.csv')\n",
    "# df = pd.merge(stats_df, salary_df)\n",
    "# df.to_csv('out.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nprint('{}\\n'.format(df))\\n\\ngroups = df.groupby('yearID')\\nfor name, group in groups:\\n    print('Year: {}'.format(name))\\n    print('{}\\n'.format(group))\\n\\nprint('{}\\n'.format(groups.get_group(2016)))\\nprint('{}\\n'.format(groups.sum()))\\nprint('{}\\n'.format(groups.mean()))\\n\\nno2015 = groups.filter(lambda x: x.name > 2015)\\nprint(no2015)\\n\""
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "print('{}\\n'.format(df))\n",
    "\n",
    "groups = df.groupby('yearID')\n",
    "for name, group in groups:\n",
    "    print('Year: {}'.format(name))\n",
    "    print('{}\\n'.format(group))\n",
    "\n",
    "print('{}\\n'.format(groups.get_group(2016)))\n",
    "print('{}\\n'.format(groups.sum()))\n",
    "print('{}\\n'.format(groups.mean()))\n",
    "\n",
    "no2015 = groups.filter(lambda x: x.name > 2015)\n",
    "print(no2015)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   T1  T2  T3\n",
      "0  10  25  16\n",
      "1  15  27  15\n",
      "2   8  25  10\n",
      "\n",
      "T1    33\n",
      "T2    77\n",
      "T3    41\n",
      "dtype: int64\n",
      "\n",
      "0    51\n",
      "1    57\n",
      "2    43\n",
      "dtype: int64\n",
      "\n",
      "T1    11.000000\n",
      "T2    25.666667\n",
      "T3    13.666667\n",
      "dtype: float64\n",
      "\n",
      "0    17.000000\n",
      "1    19.000000\n",
      "2    14.333333\n",
      "dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "  'T1': [10, 15, 8],\n",
    "  'T2': [25, 27, 25],\n",
    "  'T3': [16, 15, 10]})\n",
    "  \n",
    "print('{}\\n'.format(df))\n",
    "\n",
    "print('{}\\n'.format(df.sum()))\n",
    "\n",
    "print('{}\\n'.format(df.sum(axis=1)))\n",
    "\n",
    "print('{}\\n'.format(df.mean()))\n",
    "\n",
    "print('{}\\n'.format(df.mean(axis=1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neither function takes in a required argument. The most commonly used keyword argument for both functions is axis. The axis argument specifies whether to aggregate over rows (axis=0, the default), or columns (axis=1).\n",
    "\n",
    "In the code example, we used a DataFrame representing speed tests for three different processors (measured in seconds). When we used no argument, equivalent to using axis=0, the sum and mean functions calculated total and average times for each test. When we used axis=1, the sum and mean functions calculated total and average test times (across all three tests) for each processor.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Along with aggregating quantitative features, we can also apply weights to them. We do this through the multiply function.\n",
    "\n",
    "The multiply function takes in a list of weights or a constant as its required argument. If a constant is used, the constant is multiplied across all the rows or columns (depending on the value of axis). If a list is used, then the position of each weight in the list corresponds to which row/column it is multiplied to.\n",
    "\n",
    "In contrast with sum and mean, the default axis for multiply is the columns axis. Therefore, to multiply weights along the rows of a DataFrame, we need to explicitly set axis=0.\n",
    "\n",
    "The code below shows example usages of multiply. The df DataFrame represents three different speed tests (columns) for two different processors (rows).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      T1      T2      T3\n",
      "0    0.1    0.25    0.16\n",
      "1  150.0  240.00  100.00\n",
      "\n",
      "      T1     T2      T3\n",
      "0    0.2    0.5    0.32\n",
      "1  300.0  480.0  200.00\n",
      "\n",
      "      T1     T2     T3\n",
      "0  100.0  250.0  160.0\n",
      "1  150.0  240.0  100.0\n",
      "\n",
      "      T1     T2     T3\n",
      "0  100.0  125.0  160.0\n",
      "1  150.0  120.0  100.0\n",
      "\n",
      "0    385.0\n",
      "1    370.0\n",
      "dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "  'T1': [0.1, 150.],\n",
    "  'T2': [0.25, 240.],\n",
    "  'T3': [0.16, 100.]})\n",
    "  \n",
    "print('{}\\n'.format(df))\n",
    "\n",
    "print('{}\\n'.format(df.multiply(2)))\n",
    "\n",
    "df_ms = df.multiply([1000, 1], axis=0)\n",
    "print('{}\\n'.format(df_ms))\n",
    "\n",
    "df_w = df_ms.multiply([1,0.5,1])\n",
    "print('{}\\n'.format(df_w))\n",
    "print('{}\\n'.format(df_w.sum(axis=1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code above, the test times for processor 'p1' were measured in seconds, while the times for 'p2' were in milliseconds. So we made all the times in milliseconds by multiplying the values of 'p1' by 1000.\n",
    "\n",
    "Then we multiplied the values in 'T2' by 0.5, since those tests were done with two processors rather than one. This makes the final sum a weighted sum across the three columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    playerID  yearID teamID  HR\n",
      "0  bettsmo01    2016    BOS  31\n",
      "1   canoro01    2016    SEA  39\n",
      "2   cruzne02    2016    SEA  43\n",
      "3  ortizda01    2016    BOS  38\n",
      "4   cruzne02    2017    SEA  39\n",
      "\n",
      "0    False\n",
      "1    False\n",
      "2     True\n",
      "3    False\n",
      "4     True\n",
      "Name: playerID, dtype: bool\n",
      "\n",
      "0    False\n",
      "1    False\n",
      "2     True\n",
      "3    False\n",
      "4    False\n",
      "Name: HR, dtype: bool\n",
      "\n",
      "0    False\n",
      "1     True\n",
      "2     True\n",
      "3    False\n",
      "4     True\n",
      "Name: teamID, dtype: bool\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "  'playerID': ['bettsmo01', 'canoro01', 'cruzne02', 'ortizda01', 'cruzne02'],\n",
    "  'yearID': [2016, 2016, 2016, 2016, 2017],\n",
    "  'teamID': ['BOS', 'SEA', 'SEA', 'BOS', 'SEA'],\n",
    "  'HR': [31, 39, 43, 38, 39]})\n",
    "  \n",
    "print('{}\\n'.format(df))\n",
    "\n",
    "cruzne02 = df['playerID'] == 'cruzne02'\n",
    "print('{}\\n'.format(cruzne02))\n",
    "\n",
    "hr40 = df['HR'] > 40\n",
    "print('{}\\n'.format(hr40))\n",
    "\n",
    "notbos = df['teamID'] != 'BOS'\n",
    "print('{}\\n'.format(notbos))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    playerID  yearID teamID  HR\n",
      "0  bettsmo01    2016    BOS  31\n",
      "1   canoro01    2016    SEA  39\n",
      "2   cruzne02    2016    SEA  43\n",
      "3  ortizda01    2016    BOS  38\n",
      "4   cruzne02    2017    SEA  39\n",
      "\n",
      "0    False\n",
      "1     True\n",
      "2     True\n",
      "3    False\n",
      "4     True\n",
      "Name: playerID, dtype: bool\n",
      "\n",
      "0     True\n",
      "1    False\n",
      "2    False\n",
      "3     True\n",
      "4    False\n",
      "Name: teamID, dtype: bool\n",
      "\n",
      "0    False\n",
      "1    False\n",
      "2     True\n",
      "3    False\n",
      "4     True\n",
      "Name: playerID, dtype: bool\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "  'playerID': ['bettsmo01', 'canoro01', 'cruzne02', 'ortizda01', 'cruzne02'],\n",
    "  'yearID': [2016, 2016, 2016, 2016, 2017],\n",
    "  'teamID': ['BOS', 'SEA', 'SEA', 'BOS', 'SEA'],\n",
    "  'HR': [31, 39, 43, 38, 39]})\n",
    "  \n",
    "print('{}\\n'.format(df))\n",
    "\n",
    "str_f1 = df['playerID'].str.startswith('c')\n",
    "print('{}\\n'.format(str_f1))\n",
    "\n",
    "str_f2 = df['teamID'].str.endswith('S')\n",
    "print('{}\\n'.format(str_f2))\n",
    "\n",
    "str_f3 = ~df['playerID'].str.contains('o')\n",
    "print('{}\\n'.format(str_f3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    playerID  yearID teamID  HR\n",
      "0  bettsmo01    2016    BOS  31\n",
      "1   canoro01    2016    SEA  39\n",
      "2   cruzne02    2016    SEA  43\n",
      "3  ortizda01    2016    BOS  38\n",
      "4   cruzne02    2017    SEA  39\n",
      "\n",
      "0    False\n",
      "1    False\n",
      "2     True\n",
      "3     True\n",
      "4     True\n",
      "Name: playerID, dtype: bool\n",
      "\n",
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3    False\n",
      "4     True\n",
      "Name: yearID, dtype: bool\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "  'playerID': ['bettsmo01', 'canoro01', 'cruzne02', 'ortizda01', 'cruzne02'],\n",
    "  'yearID': [2016, 2016, 2016, 2016, 2017],\n",
    "  'teamID': ['BOS', 'SEA', 'SEA', 'BOS', 'SEA'],\n",
    "  'HR': [31, 39, 43, 38, 39]})\n",
    "  \n",
    "print('{}\\n'.format(df))\n",
    "\n",
    "isin_f1 = df['playerID'].isin(['cruzne02',\n",
    "                               'ortizda01'])\n",
    "print('{}\\n'.format(isin_f1))\n",
    "\n",
    "isin_f2 = df['yearID'].isin([2015, 2017])\n",
    "print('{}\\n'.format(isin_f2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    playerID  yearID teamID  HR\n",
      "0  bettsmo01    2016    BOS  31\n",
      "1   canoro01    2016    SEA  39\n",
      "2    doejo01    2017    NaN  99\n",
      "\n",
      "0    False\n",
      "1    False\n",
      "2     True\n",
      "Name: teamID, dtype: bool\n",
      "\n",
      "0     True\n",
      "1     True\n",
      "2    False\n",
      "Name: teamID, dtype: bool\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "  'playerID': ['bettsmo01', 'canoro01', 'doejo01'],\n",
    "  'yearID': [2016, 2016, 2017],\n",
    "  'teamID': ['BOS', 'SEA', np.nan],\n",
    "  'HR': [31, 39, 99]})\n",
    "  \n",
    "print('{}\\n'.format(df))\n",
    "\n",
    "isna = df['teamID'].isna()\n",
    "print('{}\\n'.format(isna))\n",
    "\n",
    "notna = df['teamID'].notna()\n",
    "print('{}\\n'.format(notna))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    playerID  yearID teamID  HR\n",
      "0  bettsmo01    2016    BOS  31\n",
      "1   canoro01    2016    SEA  39\n",
      "2   cruzne02    2016    SEA  43\n",
      "3  ortizda01    2016    BOS  38\n",
      "4  bettsmo01    2015    BOS  18\n",
      "\n",
      "   playerID  yearID teamID  HR\n",
      "2  cruzne02    2016    SEA  43\n",
      "\n",
      "    playerID  yearID teamID  HR\n",
      "4  bettsmo01    2015    BOS  18\n",
      "\n",
      "    playerID  yearID teamID  HR\n",
      "0  bettsmo01    2016    BOS  31\n",
      "3  ortizda01    2016    BOS  38\n",
      "4  bettsmo01    2015    BOS  18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "  'playerID': ['bettsmo01', 'canoro01', 'cruzne02', 'ortizda01', 'bettsmo01'],\n",
    "  'yearID': [2016, 2016, 2016, 2016, 2015],\n",
    "  'teamID': ['BOS', 'SEA', 'SEA', 'BOS', 'BOS'],\n",
    "  'HR': [31, 39, 43, 38, 18]})\n",
    "  \n",
    "print('{}\\n'.format(df))\n",
    "\n",
    "hr40_df = df[df['HR'] > 40]\n",
    "print('{}\\n'.format(hr40_df))\n",
    "\n",
    "not_hr30_df = df[~(df['HR'] > 30)]\n",
    "print('{}\\n'.format(not_hr30_df))\n",
    "\n",
    "str_df = df[df['teamID'].str.startswith('B')]\n",
    "print('{}\\n'.format(str_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
